name: Deploy React App to AWS EC2

on:
  push:
    branches:
      - main # Oder dein Haupt-Entwicklungsbranch
  workflow_dispatch: # Ermöglicht manuelles Auslösen

env:
  AWS_REGION: ${{ secrets.AWS_REGION }}
  TF_STATE_BUCKET: ${{ secrets.TF_STATE_BUCKET }}
  TF_STATE_DYNAMODB_TABLE: ${{ secrets.TF_STATE_DYNAMODB_TABLE }}
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }} # Für Terraform init Backend-Konfig benötigt
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }} # Für Terraform init Backend-Konfig benötigt
  # AWS_SESSION_TOKEN: ${{ secrets.AWS_SESSION_TOKEN }} # Falls du temporäre Credentials/Rollen nutzt

jobs:
  ci_build:
    name: Build React App
    runs-on: ubuntu-latest
    outputs:
      artifact_name: ${{ steps.artifact_info.outputs.artifact_name }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18' # Oder deine bevorzugte LTS Version
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json # Pfad zur Lock-Datei anpassen, falls nötig

      - name: Install dependencies
        working-directory: ./frontend
        run: npm ci

      - name: Build React app
        working-directory: ./frontend
        run: npm run build

      - name: Define artifact name
        id: artifact_info
        run: echo "artifact_name=frontend-build-${{ github.sha }}" >> $GITHUB_OUTPUT

      - name: Upload build artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ steps.artifact_info.outputs.artifact_name }}
          path: frontend/dist/ # Stelle sicher, dass dies der korrekte Build-Output-Ordner ist
          retention-days: 7

  infra_provision:
    name: Provision AWS Infrastructure with Terraform
    runs-on: ubuntu-latest
    needs: ci_build # Läuft erst nach erfolgreichem Build
    outputs: # Definiere die Outputs dieses Jobs hier
      ec2_public_ip: ${{ steps.tf_outputs.outputs.instance_public_ip }}
      ec2_user_name: ${{ steps.ec2_user_for_ssh.outputs.user_name }}
    env: # Umgebungsvariablen spezifisch für diesen Job
      TF_VAR_ssh_public_key_content: ${{ secrets.SSH_PUBLIC_KEY }} # Übergibt den Inhalt des Public Keys an Terraform
      TF_VAR_aws_region: ${{ secrets.AWS_REGION }}
      TF_VAR_ec2_user: ${{ secrets.EC2_USER }} # Übergibt den EC2_USER direkt als Terraform-Variable
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
          # aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }} # Falls verwendet

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        # with:
        #   terraform_version: "1.x.x" # Spezifische Version, falls nötig

      - name: Terraform Init
        id: init
        working-directory: ./terraform
        run: |
          terraform init \
            -backend-config="bucket=${{ env.TF_STATE_BUCKET }}" \
            -backend-config="key=react-app/terraform.tfstate" \
            -backend-config="region=${{ env.AWS_REGION }}" \
            -backend-config="dynamodb_table=${{ env.TF_STATE_DYNAMODB_TABLE }}" \
            -reconfigure

      - name: Terraform Validate
        id: validate
        working-directory: ./terraform
        run: terraform validate -no-color

      - name: Terraform Plan
        id: plan
        working-directory: ./terraform
        run: terraform plan -no-color -input=false # TF_VAR_ec2_user wird schon als ENV Var gesetzt
        continue-on-error: false

      - name: Terraform Apply
        id: apply
        working-directory: ./terraform
        run: terraform apply -auto-approve -input=false # TF_VAR_ec2_user wird schon als ENV Var gesetzt

      - name: Get Terraform Output for EC2 Public IP
        id: tf_outputs
        working-directory: ./terraform
        run: |
          echo "instance_public_ip=$(terraform output -raw instance_public_ip)" >> $GITHUB_OUTPUT

      - name: Set EC2 User for SSH output
        id: ec2_user_for_ssh
        run: echo "user_name=${{ secrets.EC2_USER }}" >> $GITHUB_OUTPUT # Nimmt den Wert aus dem Secret

  app_deploy:
    name: Deploy App to EC2
    runs-on: ubuntu-latest
    needs: infra_provision # Hängt vom infra_provision Job ab
    env:
      EC2_HOST: ${{ needs.infra_provision.outputs.ec2_public_ip }}
      EC2_USER: ${{ needs.infra_provision.outputs.ec2_user_name }}
      ARTIFACT_NAME: ${{ needs.ci_build.outputs.artifact_name }}
    steps:
      - name: Download build artifact
        uses: actions/download-artifact@v4
        with:
          name: ${{ env.ARTIFACT_NAME }}
          path: ./dist_downloaded # Lädt den Inhalt von frontend/dist/ hierhin

      - name: Setup SSH Agent
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}

      - name: Debug Connection Info Before SSH
        run: |
          echo "Attempting to connect to host: ${{ env.EC2_HOST }}"
          echo "Using user: ${{ env.EC2_USER }}"
          if [ -z "${{ env.EC2_HOST }}" ]; then echo "EC2_HOST is empty!"; exit 1; fi
          if [ -z "${{ env.EC2_USER }}" ]; then echo "EC2_USER is empty!"; exit 1; fi

      - name: Create target directory on EC2 and set permissions
        run: |
          ssh -v -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            "${{ env.EC2_USER }}@${{ env.EC2_HOST }}" \
            'sudo mkdir -p /var/www/html/app && sudo chown -R ${{ env.EC2_USER }}:${{ env.EC2_USER }} /var/www/html/app'

      - name: Deploy artifact to EC2
        run: |
          scp -v -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -r \
            ./dist_downloaded/* \
            "${{ env.EC2_USER }}@${{ env.EC2_HOST }}:/var/www/html/app/" # Sicherstellen, dass der Zielpfad mit / endet für Verzeichnisse

      - name: Reload Nginx on EC2
        run: |
          ssh -v -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            "${{ env.EC2_USER }}@${{ env.EC2_HOST }}" \
            'sudo systemctl reload nginx'

      - name: Verify Deployment (Smoke Test)
        run: |
          sleep 10 # Gib Nginx etwas Zeit
          echo "Verifying health endpoint: http://${{ env.EC2_HOST }}/health.html"
          curl -Isf http://${{ env.EC2_HOST }}/health.html
          echo "Verifying main page: http://${{ env.EC2_HOST }}/"
          curl -Isf http://${{ env.EC2_HOST }}/